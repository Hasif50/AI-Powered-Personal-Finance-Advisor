{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Data EDA and Preprocessing\n",
    "**From Hasif's Workspace**\n",
    "\n",
    "This notebook performs exploratory data analysis and preprocessing on financial transaction data for the AI-Powered Personal Finance Advisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data for demonstration\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from generate_synthetic_data import generate_transactions\n",
    "\n",
    "# Generate sample data\n",
    "df = generate_transactions(1000)\n",
    "print(f\"Generated {len(df)} transactions\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Data types:\\n{df.dtypes}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Add time-based features\n",
    "df['day_of_week'] = df['date'].dt.day_name()\n",
    "df['month'] = df['date'].dt.month_name()\n",
    "df['quarter'] = df['date'].dt.to_period('Q').astype(str)\n",
    "df['is_weekend'] = df['date'].dt.dayofweek.isin([5, 6])\n",
    "\n",
    "print(\"Time-based features added successfully!\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction distribution by category\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "category_counts = df['category'].value_counts()\n",
    "plt.pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Transaction Distribution by Category')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "category_amounts = df.groupby('category')['amount'].sum().sort_values(ascending=False)\n",
    "plt.bar(range(len(category_amounts)), category_amounts.values)\n",
    "plt.xticks(range(len(category_amounts)), category_amounts.index, rotation=45)\n",
    "plt.title('Total Amount by Category')\n",
    "plt.ylabel('Amount ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spending patterns over time\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Daily spending trend\n",
    "plt.subplot(2, 2, 1)\n",
    "daily_spending = df[df['transaction_type'] == 'Debit'].groupby('date')['amount'].sum()\n",
    "plt.plot(daily_spending.index, daily_spending.values)\n",
    "plt.title('Daily Spending Trend')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Amount ($)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Weekly pattern\n",
    "plt.subplot(2, 2, 2)\n",
    "weekly_pattern = df[df['transaction_type'] == 'Debit'].groupby('day_of_week')['amount'].sum()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekly_pattern = weekly_pattern.reindex(day_order)\n",
    "plt.bar(weekly_pattern.index, weekly_pattern.values)\n",
    "plt.title('Weekly Spending Pattern')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Total Amount ($)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Monthly pattern\n",
    "plt.subplot(2, 2, 3)\n",
    "monthly_pattern = df[df['transaction_type'] == 'Debit'].groupby('month')['amount'].sum()\n",
    "plt.bar(monthly_pattern.index, monthly_pattern.values)\n",
    "plt.title('Monthly Spending Pattern')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Amount ($)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Amount distribution\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(df['amount'], bins=50, alpha=0.7)\n",
    "plt.title('Transaction Amount Distribution')\n",
    "plt.xlabel('Amount ($)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features for analysis\n",
    "df_sorted = df.sort_values('date')\n",
    "\n",
    "# Rolling statistics\n",
    "df_sorted['rolling_mean_7'] = df_sorted['amount'].rolling(window=7, min_periods=1).mean()\n",
    "df_sorted['rolling_std_7'] = df_sorted['amount'].rolling(window=7, min_periods=1).std()\n",
    "\n",
    "# Lagged features\n",
    "df_sorted['amount_lag_1'] = df_sorted['amount'].shift(1)\n",
    "df_sorted['amount_lag_7'] = df_sorted['amount'].shift(7)\n",
    "\n",
    "# Z-score for anomaly detection\n",
    "df_sorted['amount_zscore'] = (df_sorted['amount'] - df_sorted['amount'].mean()) / df_sorted['amount'].std()\n",
    "\n",
    "print(\"Feature engineering completed!\")\n",
    "print(f\"New features: {['rolling_mean_7', 'rolling_std_7', 'amount_lag_1', 'amount_lag_7', 'amount_zscore']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers using IQR method\n",
    "Q1 = df['amount'].quantile(0.25)\n",
    "Q3 = df['amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df['amount'] < lower_bound) | (df['amount'] > upper_bound)]\n",
    "print(f\"Number of outliers: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Display outliers\n",
    "if len(outliers) > 0:\n",
    "    print(\"\\nOutlier transactions:\")\n",
    "    print(outliers[['date', 'description', 'amount', 'category']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "numeric_cols = df_sorted.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df_sorted[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "output_path = '../data/processed_transactions.csv'\n",
    "df_sorted.to_csv(output_path, index=False)\n",
    "print(f\"Processed data saved to {output_path}\")\n",
    "\n",
    "# Summary of the processed dataset\n",
    "print(f\"\\nFinal dataset shape: {df_sorted.shape}\")\n",
    "print(f\"Date range: {df_sorted['date'].min()} to {df_sorted['date'].max()}\")\n",
    "print(f\"Total amount: ${df_sorted['amount'].sum():,.2f}\")\n",
    "print(f\"Categories: {df_sorted['category'].nunique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
